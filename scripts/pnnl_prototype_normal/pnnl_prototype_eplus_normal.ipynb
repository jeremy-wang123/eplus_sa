{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnergyPlus Parameterization and Sensitivity Analysis for Residential Single Family Homes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daniel Xu, Keller Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created in order to document the workflow and processes of EnergyPlus within Python. This is for my project involving the parameterization of EnergyPlus. Given that EnergyPlus has over 2000 available inputs, more research needs to be done in order to document which parameters are most significant and relevant in home energy modeling and simulations. \n",
    "\n",
    "The goal of this project is to run EnergyPlus on a model single family residential home. Some of the inputs will be fixed to default variables. Other variables, such as window thickness, thermostat set-points, etc. will be varied on pre-defined distributions. \n",
    "\n",
    "This paper uses PNNL's pre-defined archetype to model a single family home. The model is located in climate zone 6A and has a heat pump and heated basement. A description can be found here: https://www.energycodes.gov/prototype-building-models#Residential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For working with IDF files and EnergyPlus\n",
    "from eppy import modeleditor\n",
    "from eppy.modeleditor import IDF\n",
    "\n",
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For file and directory operations\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# For working with time and dates\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# For HTTP requests\n",
    "import requests\n",
    "\n",
    "# For running external commands\n",
    "import subprocess\n",
    "\n",
    "# For reading ESO output files\n",
    "import esoreader\n",
    "\n",
    "# For working with weather data and EPW files\n",
    "import diyepw\n",
    "\n",
    "# For working with directories\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting EnergyPlus Input Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd_file_path = \"/Applications/EnergyPlus-24-2-0/Energy+.idd\"\n",
    "IDF.setiddname(idd_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a Skeleton IDF File \n",
    "\n",
    "This modifiable IDF file is provided by EnergyPlus in its initial download. It provides a mock residential home in Chicago with multiple zones. I will assume that some of the inputs are fixed and others are varied on a distribution. \n",
    "\n",
    "Directly from the EnergyPlus documentation: \n",
    "\n",
    "\"This file does the basic test of an air distribution system in a residential home. A two speed heat pump with a supplmental gas heater provides space heating and cooling. It provides ventilation through the ZoneAirBalance:OutdoorAir model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfname = \"../../data/US+SF+CZ6A+hp+heatedbsmt+IECC_2024.idf\"\n",
    "\n",
    "preidf = IDF(idfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the IDF file in the EnergyPlus IDF editor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preidf.printidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the location of the prototype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preidf.idfobjects['Site:Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Station Data Retrieval for EnergyPlus Simulations\n",
    "\n",
    "This project aims to enhance the accuracy of building energy simulations by sourcing precise local weather data. By leveraging the NCEI (National Centers for Environmental Information) API, we are able to identify and retrieve data from the nearest weather station to any specified location. This localized weather data is crucial for feeding into EnergyPlus simulations, ensuring that our building models operate under realistic environmental conditions. The accurate simulation of energy usage and needs based on actual weather data helps in designing more efficient and sustainable buildings.\n",
    "\n",
    "For more detailed information on how to utilize the NCEI API, including obtaining access tokens and making API requests, please visit the NCEI Web Services Documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_active_weather_stations(api_key, lat, lon):\n",
    "#     base_url = 'https://www.ncei.noaa.gov/cdo-web/api/v2/stations'\n",
    "#     headers = {'token': api_key}\n",
    "#     # Define the date one year ago from today\n",
    "#     one_year_ago = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "\n",
    "#     # Set the request to retrieve more stations for a broader check\n",
    "#     params = {\n",
    "#         'extent': f'{lat-0.05},{lon-0.05},{lat+0.05},{lon+0.05}',\n",
    "#         'limit': '1000',  # Adjust limit as needed\n",
    "#         'sortfield': 'mindate',\n",
    "#         'sortorder': 'desc'\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(base_url, headers=headers, params=params)\n",
    "    \n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n",
    "#         return []\n",
    "\n",
    "#     try:\n",
    "#         data = response.json()\n",
    "#         active_stations = []\n",
    "#         # Filter stations by checking if the 'maxdate' is within the last year\n",
    "#         for station in data.get('results', []):\n",
    "#             if station['maxdate'] >= one_year_ago:\n",
    "#                 active_stations.append(station)\n",
    "#         return active_stations\n",
    "#     except ValueError:\n",
    "#         print(\"Failed to decode JSON from response.\")\n",
    "#         return []\n",
    "\n",
    "# api_key = 'SrgpVmvZhbtZXRSdBgknhaRSQlhTNzBt'\n",
    "# latitude = 41.78  \n",
    "# longitude = -87.75  \n",
    "\n",
    "# active_stations = get_active_weather_stations(api_key, latitude, longitude)\n",
    "# print(f\"Found {len(active_stations)} active stations:\")\n",
    "# for station in active_stations:\n",
    "#     print(station)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this location, we will then use the diyepw package to create time series weather data. More information about diyepw can be found at: \n",
    "\n",
    "https://diyepw.readthedocs.io/en/latest/tutorial.html (PNNL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory and store it\n",
    "scripts_dir = os.getcwd()\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "os.makedirs(\"weather_data\", exist_ok=True)\n",
    "\n",
    "# Changing to this directory\n",
    "os.chdir(\"weather_data\")\n",
    "\n",
    "diyepw.create_amy_epw_files_for_years_and_wmos(\n",
    "  [2022,2023,2024],\n",
    "  [726440],\n",
    "  max_records_to_interpolate=6,\n",
    "  max_records_to_impute=48,\n",
    "  max_missing_amy_rows=20,\n",
    "  allow_downloads=True,\n",
    ")\n",
    "\n",
    "# Change back to the scripts directory\n",
    "os.chdir(scripts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_idf_dir = 'randomized_idfs'\n",
    "    \n",
    "# Create the output directory if it does not exist\n",
    "os.makedirs(output_idf_dir, exist_ok=True)\n",
    "\n",
    "# Remove all files and subdirectories inside the directory\n",
    "for filename in os.listdir(output_idf_dir):\n",
    "    file_path = os.path.join(output_idf_dir, filename)\n",
    "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)  # Delete the file or symbolic link\n",
    "    elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)  # Delete the subdirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing IDF parameters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_building_parameters_normal_dist(skeleton_idf_path, idd_file_path, output_idf_dir, verbose=True):\n",
    "    # Load the EnergyPlus IDD file\n",
    "    IDF.setiddname(idd_file_path)\n",
    "    if verbose:\n",
    "        print(f\"IDD set from: {idd_file_path}\")\n",
    "\n",
    "    # Means from the original IDF\n",
    "    mean_heating_sp = 22.0  # °C\n",
    "    mean_cooling_sp = 26.6  # °C\n",
    "    mean_people_per_area = 3.0  # people\n",
    "    mean_infil_flow_rate = 0.01  # m3/s # sokol\n",
    "    mean_watts_equip = 500  # W # sokol\n",
    "    mean_watts_lights = 1000  # W # sokol\n",
    "\n",
    "    sd = 0.05\n",
    "\n",
    "    # Calculating standard deviations\n",
    "    sd_heating_sp = sd * mean_heating_sp\n",
    "    sd_cooling_sp = sd * mean_cooling_sp\n",
    "    sd_people_per_area = sd * mean_people_per_area\n",
    "    sd_infil_flow_rate = sd * mean_infil_flow_rate\n",
    "    sd_mean_watts_equip = sd * mean_watts_equip\n",
    "    sd_mean_watts_lights = sd * mean_watts_lights\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Starting parameter updates for 10 iterations.\")\n",
    "    for i in range(10):\n",
    "        if verbose:\n",
    "            print(f\"\\n--- Iteration {i+1}/10 ---\")\n",
    "        # Load the IDF file\n",
    "        idf = IDF(skeleton_idf_path)\n",
    "        if verbose:\n",
    "            print(f\"Loaded skeleton IDF file: {skeleton_idf_path}\")\n",
    "\n",
    "        # Draw new heating and cooling setpoints from normal distributions\n",
    "        valid_setpoints = False\n",
    "        while not valid_setpoints:\n",
    "            new_heating_setpoint = np.random.normal(mean_heating_sp, sd_heating_sp)\n",
    "            new_cooling_setpoint = np.random.normal(mean_cooling_sp, sd_cooling_sp)\n",
    "            if new_heating_setpoint > 0 and new_cooling_setpoint > 0 and (new_cooling_setpoint - new_heating_setpoint > 2):\n",
    "                valid_setpoints = True\n",
    "        if verbose:\n",
    "            print(f\"New heating setpoint: {new_heating_setpoint:.2f}°C, cooling setpoint: {new_cooling_setpoint:.2f}°C\")\n",
    "\n",
    "        # Draw new people per area value\n",
    "        new_people_per_area = np.random.normal(mean_people_per_area, sd_people_per_area)\n",
    "        while new_people_per_area < 0.0:\n",
    "            new_people_per_area = np.random.normal(mean_people_per_area, sd_people_per_area)\n",
    "        if verbose:\n",
    "            print(f\"New people per area: {new_people_per_area:.6f} people/m²\")\n",
    "\n",
    "        # Assign different infiltration rates for different zones\n",
    "        new_infil_flow_rate_living = np.random.normal(mean_infil_flow_rate, sd_infil_flow_rate)\n",
    "        while new_infil_flow_rate_living < 0.0:\n",
    "            new_infil_flow_rate_living = np.random.normal(mean_infil_flow_rate, sd_infil_flow_rate)\n",
    "        new_infil_flow_rate_garage = np.random.normal(mean_infil_flow_rate, sd_infil_flow_rate)\n",
    "        while new_infil_flow_rate_garage < 0.0:\n",
    "            new_infil_flow_rate_garage = np.random.normal(mean_infil_flow_rate, sd_infil_flow_rate)\n",
    "        new_infil_flow_rate_attic = np.random.normal(mean_infil_flow_rate, sd_infil_flow_rate)\n",
    "        while new_infil_flow_rate_attic < 0.0:\n",
    "            new_infil_flow_rate_attic = np.random.normal(mean_infil_flow_rate, sd_infil_flow_rate)\n",
    "        if verbose:\n",
    "            print(f\"New infiltration rates (m³/s): Living: {new_infil_flow_rate_living:.6e}, Garage: {new_infil_flow_rate_garage:.6e}, Attic: {new_infil_flow_rate_attic:.6e}\")\n",
    "\n",
    "        # Draw new equipment and lighting power values\n",
    "        new_watts_equip = np.random.normal(mean_watts_equip, sd_mean_watts_equip)\n",
    "        while new_watts_equip < 0.0:\n",
    "            new_watts_equip = np.random.normal(mean_watts_equip, sd_mean_watts_equip)\n",
    "        new_watts_lights = np.random.normal(mean_watts_lights, sd_mean_watts_lights)\n",
    "        while new_watts_lights < 0.0:\n",
    "            new_watts_lights = np.random.normal(mean_watts_lights, sd_mean_watts_lights)\n",
    "        if verbose:\n",
    "            print(f\"New equipment power: {new_watts_equip:.1f} W, new lighting power: {new_watts_lights:.1f} W\")\n",
    "            \n",
    "        # Update Simulation Control \n",
    "        \n",
    "        try: \n",
    "            sim_control = idf.getobject('SimulationControl')\n",
    "            sim_control.fieldvalues[4] = \"No\"\n",
    "            sim_control.fieldvalues[5] = \"Yes\"\n",
    "            if verbose:\n",
    "                print(\"Updated SimulationControl to run simulation for weather file run periods.\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating SimulationControl:\", e)\n",
    "\n",
    "        # Update building parameters\n",
    "        try:\n",
    "            people_object = idf.getobject('PEOPLE', 'LIVING ZONE People')\n",
    "            people_object.fieldvalues[5] = new_people_per_area\n",
    "            if verbose:\n",
    "                print(f\"Updated PEOPLE object 'LIVING ZONE People' with value: {new_people_per_area:.6f}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating PEOPLE object:\", e)\n",
    "\n",
    "        try:\n",
    "            infiltration_object_living = idf.getobject('ZONEINFILTRATION:DESIGNFLOWRATE', 'LIVING ZONE Infil 1')\n",
    "            infiltration_object_living.fieldvalues[5] = new_infil_flow_rate_living\n",
    "            if verbose:\n",
    "                print(f\"Updated infiltration for Living Zone to: {new_infil_flow_rate_living:.6e}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating infiltration for Living Zone:\", e)\n",
    "\n",
    "        try:\n",
    "            infiltration_object_garage = idf.getobject('ZONEINFILTRATION:DESIGNFLOWRATE', 'GARAGE ZONE Infil 1')\n",
    "            infiltration_object_garage.fieldvalues[5] = new_infil_flow_rate_garage\n",
    "            if verbose:\n",
    "                print(f\"Updated infiltration for Garage Zone to: {new_infil_flow_rate_garage:.6e}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating infiltration for Garage Zone:\", e)\n",
    "\n",
    "        try:\n",
    "            infiltration_object_attic = idf.getobject('ZONEINFILTRATION:DESIGNFLOWRATE', 'ATTIC ZONE Infil 1')\n",
    "            infiltration_object_attic.fieldvalues[5] = new_infil_flow_rate_attic\n",
    "            if verbose:\n",
    "                print(f\"Updated infiltration for Attic Zone to: {new_infil_flow_rate_attic:.6e}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating infiltration for Attic Zone:\", e)\n",
    "\n",
    "        try:\n",
    "            lighting_object = idf.getobject('LIGHTS', 'LIVING ZONE Lights')\n",
    "            lighting_object.Lighting_Level = new_watts_lights\n",
    "            if verbose:\n",
    "                print(f\"Updated LIGHTS object 'LIVING ZONE Lights' with Lighting_Level: {new_watts_lights:.1f} W\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating LIGHTS object:\", e)\n",
    "\n",
    "        try:\n",
    "            equipment_object = idf.getobject('ELECTRICEQUIPMENT', 'LIVING ZONE ElecEq')\n",
    "            equipment_object.Design_Level = new_watts_equip\n",
    "            if verbose:\n",
    "                print(f\"Updated ELECTRICEQUIPMENT 'LIVING ZONE ElecEq' with Design_Level: {new_watts_equip:.1f} W\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating ELECTRICEQUIPMENT object:\", e)\n",
    "\n",
    "        try:\n",
    "            heating_schedule = idf.getobject('SCHEDULE:COMPACT', 'Dual Heating Setpoints')\n",
    "            heating_schedule.fieldvalues[6] = str(round(new_heating_setpoint, 2))\n",
    "            if verbose:\n",
    "                print(f\"Updated 'Dual Heating Setpoints' to: {round(new_heating_setpoint, 2)}°C\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating Dual Heating Setpoints:\", e)\n",
    "\n",
    "        try:\n",
    "            cooling_schedule = idf.getobject('SCHEDULE:COMPACT', 'Dual Cooling Setpoints')\n",
    "            cooling_schedule.fieldvalues[6] = str(round(new_cooling_setpoint, 2))\n",
    "            if verbose:\n",
    "                print(f\"Updated 'Dual Cooling Setpoints' to: {round(new_cooling_setpoint, 2)}°C\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Error updating Dual Cooling Setpoints:\", e)\n",
    "\n",
    "        output_file_path = f\"{output_idf_dir}/randomized_{i+1}.idf\"\n",
    "        idf.save(output_file_path)\n",
    "        if verbose:\n",
    "            print(f\"Saved updated IDF file to: {output_file_path}\")\n",
    "\n",
    "# Example usage:\n",
    "skeleton_idf_path = idfname  # Assuming idfname is defined elsewhere as the skeleton IDF path.\n",
    "update_building_parameters_normal_dist(skeleton_idf_path, idd_file_path, output_idf_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the simulation and outputting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sim_dir = 'output'\n",
    "    \n",
    "# Create the output directory if it does not exist\n",
    "os.makedirs(output_sim_dir, exist_ok=True)\n",
    "\n",
    "# Remove all files and subdirectories inside the directory\n",
    "for filename in os.listdir(output_sim_dir):\n",
    "    file_path = os.path.join(output_sim_dir, filename)\n",
    "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)  # Delete the file or symbolic link\n",
    "    elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)  # Delete the subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your directories and files\n",
    "idf_dir = \"randomized_idfs\"\n",
    "weather_file = \"weather_data/USA_IL_Chicago-OHare-Intl-AP.725300_AMY_2023.epw\"\n",
    "idd_file_path = \"/Applications/EnergyPlus-24-2-0/Energy+.idd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_energyplus_simulation(output_idf_dir, weather_file, idd_file_path, output_sim_dir):\n",
    "    # Set the IDD file path\n",
    "    IDF.setiddname(idd_file_path)\n",
    "    \n",
    "    # Get the list of IDF files\n",
    "    idf_files = [f for f in os.listdir(output_idf_dir) if f.endswith('.idf')]\n",
    "    \n",
    "    for idf_file in idf_files:\n",
    "        # Define paths\n",
    "        idf_path = os.path.join(output_idf_dir, idf_file)\n",
    "        idf_output_dir = os.path.join(output_sim_dir, os.path.splitext(idf_file)[0])\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(idf_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load the IDF file\n",
    "        idf = IDF(idf_path)\n",
    "        \n",
    "        # Save a copy of the IDF file in the output directory\n",
    "        idf_copy_path = os.path.join(idf_output_dir, os.path.basename(idf_path))\n",
    "        idf.save(idf_copy_path)\n",
    "        \n",
    "        # Run the EnergyPlus simulation\n",
    "        subprocess.run([\n",
    "            'energyplus', \n",
    "            '--weather', weather_file, \n",
    "            '--output-directory', idf_output_dir, \n",
    "            '--idd', idd_file_path, \n",
    "            '--annual',\n",
    "            '--readvars',\n",
    "            idf_copy_path\n",
    "        ])\n",
    "\n",
    "run_energyplus_simulation(output_idf_dir, weather_file, idd_file_path, output_sim_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_frames = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    folder_name = f\"randomized_{i}\"\n",
    "    file_path = os.path.join(output_sim_dir, folder_name, \"eplusmtr.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        # Tag this data with a Simulation ID\n",
    "        temp_df[\"Simulation_ID\"] = i\n",
    "        \n",
    "        all_data_frames.append(temp_df)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Combine everything into one DataFrame\n",
    "combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(combined_df.head())\n",
    "\n",
    "# Print some info about the final DataFrame\n",
    "print(\"Combined DataFrame shape:\", combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory where you want to save the CSV\n",
    "analysis_dir = '/Users/danielxu/Desktop/Dartmouth College/6. Keller Lab/24S/eplus_sensitivity/analysis'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(analysis_dir, exist_ok=True)\n",
    "\n",
    "# Create a file path for the output CSV\n",
    "output_csv_path = os.path.join(analysis_dir, 'combined_sims.csv')\n",
    "\n",
    "combined_df[\"Electricity:Facility [J](Monthly)\"] = pd.to_numeric(\n",
    "    combined_df[\"Electricity:Facility [J](Monthly)\"], \n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Write the combined DataFrame to CSV\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Data has been written to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example path to your combined CSV file\n",
    "analysis_dir = '/Users/danielxu/Desktop/Dartmouth College/6. Keller Lab/24S/eplus_sensitivity/analysis'\n",
    "csv_path = os.path.join(analysis_dir, 'combined_sims.csv')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Box Plot - Distribution of Facility Electricity by Month Across Simulations\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Date/Time', y='Electricity:Facility [J](Monthly)', data=df)\n",
    "plt.title('Distribution of Facility Electricity by Month (All Simulations)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Facility Electricity (J)')\n",
    "plt.xticks(rotation=45)  # Rotate month labels if needed\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2) Line Plot - Each Simulation's Monthly Electricity Use\n",
    "# -----------------------------------------------------------------------------\n",
    "# This approach transforms the DataFrame into wide format, where each Simulation\n",
    "# has a row, and each Month is a column. Then it plots all simulations as lines.\n",
    "\n",
    "# Pivot so we have one row per Simulation_ID and one column per Month\n",
    "# Define your month order\n",
    "month_order = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n",
    "               \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "# Convert the Date/Time column to a Categorical with the specified order\n",
    "df[\"Date/Time\"] = pd.Categorical(\n",
    "    df[\"Date/Time\"], \n",
    "    categories=month_order, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Now pivot again. The columns will appear in the custom order\n",
    "pivoted = df.pivot_table(\n",
    "    index='Simulation_ID',\n",
    "    columns='Date/Time',\n",
    "    values='Electricity:Facility [J](Monthly)'\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "pivoted.T.plot(legend=False)  # Transpose so Months go to the x-axis\n",
    "plt.title('Electricity:Facility by Month for All Simulations')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Facility Electricity (J)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = df[df[\"Date/Time\"] == \"July\"]\n",
    "if not jan_df.empty:\n",
    "    sns.displot(\n",
    "        data=jan_df,\n",
    "        x=\"Electricity:Facility [J](RunPeriod)\",\n",
    "        kind=\"kde\",\n",
    "        fill=True\n",
    "    )\n",
    "    plt.title(\"Facility Electricity Distribution\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data found for January.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df has columns \"Simulation_ID\" and \"Electricity:Facility [J](Monthly)\"\n",
    "\n",
    "# Sum the electricity usage for each simulation\n",
    "df_summed = (\n",
    "    df\n",
    "    .groupby(\"Simulation_ID\")[\"Electricity:Facility [J](Monthly)\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"Total_Electricity\")\n",
    ")\n",
    "\n",
    "# Plot the probability density of total electricity usage\n",
    "sns.displot(data=df_summed, x=\"Total_Electricity\", kind=\"kde\", fill=True)\n",
    "plt.title(\"Probability Distribution of Total Electricity Usage (All Simulations)\")\n",
    "plt.xlabel(\"Total Electricity (J)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ESO = '/Users/danielxu/Desktop/Dartmouth College/6. Keller Lab/24S/eplus_sensitivity/scripts/output/randomized_92/eplusout.eso'\n",
    "eso = esoreader.read_from_path(PATH_TO_ESO)\n",
    "\n",
    "variables = eso.dd.find_variable('Energy')\n",
    "\n",
    "print(variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = eso.dd.index[('TimeStep,REPORTSCH', 'ACDXCOIL 1', 'Cooling Coil Total Cooling Energy')]\n",
    "\n",
    "data = eso.data[index]\n",
    "\n",
    "print(data)\n",
    "# print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start date and the time step duration (10 minutes for 6 steps per hour)\n",
    "start_date = datetime(2024, 1, 1, 0, 0)\n",
    "time_step_duration = timedelta(minutes=10)\n",
    "\n",
    "# Define the schedule\n",
    "schedule = [\n",
    "    (datetime(2024, 1, 1), datetime(2024, 1, 20), 0.0),\n",
    "    (datetime(2024, 1, 21), datetime(2024, 1, 21), 1.0),\n",
    "    (datetime(2024, 1, 22), datetime(2024, 7, 20), 0.0),\n",
    "    (datetime(2024, 7, 21), datetime(2024, 7, 21), 1.0),\n",
    "    (datetime(2024, 7, 22), datetime(2024, 12, 31), 0.0),\n",
    "]\n",
    "\n",
    "# Generate a list of timestamps and corresponding schedule values\n",
    "timestamps = []\n",
    "schedule_values = []\n",
    "current_time = start_date\n",
    "\n",
    "for energy_value in data:\n",
    "    # Find the applicable schedule value for the current time\n",
    "    schedule_value = next(value for start, end, value in schedule if start <= current_time <= end)\n",
    "    timestamps.append(current_time)\n",
    "    schedule_values.append(schedule_value)\n",
    "    current_time += time_step_duration\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Timestamp': timestamps,\n",
    "    'Schedule_Value': schedule_values,\n",
    "    'Energy_Use': data\n",
    "})\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df.to_csv('aligned_energy_use_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eplus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
